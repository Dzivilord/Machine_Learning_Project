{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db02cefb",
   "metadata": {},
   "source": [
    "# Import thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "203c7907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing  import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ef5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tracemalloc\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db93ed",
   "metadata": {},
   "source": [
    "# Đọc dữ liệu đầu vào"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a261931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='../../dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50274dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + '/train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "with open(data_path + '/test.json', 'r') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e6b1a8",
   "metadata": {},
   "source": [
    "# Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a81a7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= pd.DataFrame(train_data)\n",
    "test_data= pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24b0c5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1195 entries, 0 to 1194\n",
      "Data columns (total 5 columns):\n",
      " #   Column                           Non-Null Count  Dtype \n",
      "---  ------                           --------------  ----- \n",
      " 0   audio_embedding                  1195 non-null   object\n",
      " 1   is_turkey                        1195 non-null   int64 \n",
      " 2   vid_id                           1195 non-null   object\n",
      " 3   end_time_seconds_youtube_clip    1195 non-null   int64 \n",
      " 4   start_time_seconds_youtube_clip  1195 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 46.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e7a5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings=train_data['audio_embedding'].apply(np.array)\n",
    "max_len = train_embeddings.apply(len).max()\n",
    "embedding_dim = len(train_embeddings.iloc[0][0])\n",
    "train_X = pad_sequences(train_embeddings, maxlen=max_len, dtype='float32', padding='post', truncating='post')\n",
    "train_Y = train_data['is_turkey'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35c2f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx = test_data['audio_embedding'].apply(lambda x: isinstance(x, list) and len(x) > 0)\n",
    "test_embeddings = test_data.loc[valid_idx, 'audio_embedding'].apply(np.array)\n",
    "test_X = pad_sequences(test_embeddings, maxlen=max_len, dtype='float32', padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4398641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, T, D = train_X.shape\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_X.reshape(-1, D)).reshape(B, T, D)\n",
    "test_X = scaler.transform(test_X.reshape(-1, D)).reshape(test_X.shape[0], T, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e7ace5",
   "metadata": {},
   "source": [
    "# Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef380f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bước 1: Split gốc\n",
    "train_X_, val_X, train_Y_, val_Y = train_test_split(train_X, train_Y, test_size=0.3, random_state=45)\n",
    "\n",
    "# Bước 2: Augment **chỉ tập train**\n",
    "noise = np.random.normal(0, 0.01, size=train_X_.shape)\n",
    "train_X_noisy = train_X_ + noise\n",
    "\n",
    "# Bước 3: Nối lại tập train mở rộng\n",
    "X_tr_aug = np.concatenate([train_X_, train_X_noisy], axis=0)\n",
    "y_tr_aug = np.concatenate([train_Y_, train_Y_], axis=0)\n",
    "\n",
    "# Bước 4: reshape & convert sang Tensor\n",
    "X_tr_cnn = torch.tensor(X_tr_aug.reshape(-1, T, D), dtype=torch.float32)\n",
    "y_tr = torch.tensor(y_tr_aug, dtype=torch.float32)\n",
    "\n",
    "X_val_cnn = torch.tensor(val_X.reshape(-1, T, D), dtype=torch.float32)\n",
    "y_val = torch.tensor(val_Y, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb72ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.pool(x).squeeze(-1)\n",
    "        w = self.fc(w).unsqueeze(-1)\n",
    "        return x * w\n",
    "\n",
    "class AudioCNNWithSE(nn.Module):\n",
    "    def __init__(self, in_channels=128, out_channels=64, fc_out=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, 3, padding=1)\n",
    "        self.se1 = SEBlock(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels * 2, 3, padding=1)\n",
    "        self.se2 = SEBlock(out_channels * 2)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(out_channels * 2, fc_out)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.drop(self.se1(F.relu(self.conv1(x))))\n",
    "        x = self.drop(self.se2(F.relu(self.conv2(x))))\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba21e559",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AudioCNNWithSE()  # or num_classes=3 if 3 classes\n",
    "criterion = nn.BCEWithLogitsLoss()  # dùng nếu output là sigmoid (nhị phân)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5,weight_decay=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe66c729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 0.6926, Val Loss: 0.6915\n",
      "Epoch 1, Train Loss: 0.6908, Val Loss: 0.6897\n",
      "Epoch 2, Train Loss: 0.6892, Val Loss: 0.6878\n",
      "Epoch 3, Train Loss: 0.6872, Val Loss: 0.6858\n",
      "Epoch 4, Train Loss: 0.6853, Val Loss: 0.6836\n",
      "Epoch 5, Train Loss: 0.6831, Val Loss: 0.6812\n",
      "Epoch 6, Train Loss: 0.6809, Val Loss: 0.6786\n",
      "Epoch 7, Train Loss: 0.6780, Val Loss: 0.6755\n",
      "Epoch 8, Train Loss: 0.6748, Val Loss: 0.6720\n",
      "Epoch 9, Train Loss: 0.6714, Val Loss: 0.6682\n",
      "Epoch 10, Train Loss: 0.6672, Val Loss: 0.6638\n",
      "Epoch 11, Train Loss: 0.6630, Val Loss: 0.6590\n",
      "Epoch 12, Train Loss: 0.6580, Val Loss: 0.6536\n",
      "Epoch 13, Train Loss: 0.6525, Val Loss: 0.6474\n",
      "Epoch 14, Train Loss: 0.6462, Val Loss: 0.6407\n",
      "Epoch 15, Train Loss: 0.6392, Val Loss: 0.6332\n",
      "Epoch 16, Train Loss: 0.6315, Val Loss: 0.6251\n",
      "Epoch 17, Train Loss: 0.6237, Val Loss: 0.6163\n",
      "Epoch 18, Train Loss: 0.6150, Val Loss: 0.6069\n",
      "Epoch 19, Train Loss: 0.6054, Val Loss: 0.5967\n",
      "Epoch 20, Train Loss: 0.5952, Val Loss: 0.5861\n",
      "Epoch 21, Train Loss: 0.5845, Val Loss: 0.5748\n",
      "Epoch 22, Train Loss: 0.5734, Val Loss: 0.5630\n",
      "Epoch 23, Train Loss: 0.5619, Val Loss: 0.5508\n",
      "Epoch 24, Train Loss: 0.5496, Val Loss: 0.5382\n",
      "Epoch 25, Train Loss: 0.5375, Val Loss: 0.5254\n",
      "Epoch 26, Train Loss: 0.5251, Val Loss: 0.5123\n",
      "Epoch 27, Train Loss: 0.5119, Val Loss: 0.4989\n",
      "Epoch 28, Train Loss: 0.4994, Val Loss: 0.4856\n",
      "Epoch 29, Train Loss: 0.4867, Val Loss: 0.4725\n",
      "Epoch 30, Train Loss: 0.4729, Val Loss: 0.4590\n",
      "Epoch 31, Train Loss: 0.4605, Val Loss: 0.4456\n",
      "Epoch 32, Train Loss: 0.4478, Val Loss: 0.4323\n",
      "Epoch 33, Train Loss: 0.4345, Val Loss: 0.4194\n",
      "Epoch 34, Train Loss: 0.4226, Val Loss: 0.4063\n",
      "Epoch 35, Train Loss: 0.4100, Val Loss: 0.3937\n",
      "Epoch 36, Train Loss: 0.3982, Val Loss: 0.3814\n",
      "Epoch 37, Train Loss: 0.3870, Val Loss: 0.3695\n",
      "Epoch 38, Train Loss: 0.3750, Val Loss: 0.3578\n",
      "Epoch 39, Train Loss: 0.3643, Val Loss: 0.3464\n",
      "Epoch 40, Train Loss: 0.3532, Val Loss: 0.3355\n",
      "Epoch 41, Train Loss: 0.3434, Val Loss: 0.3247\n",
      "Epoch 42, Train Loss: 0.3334, Val Loss: 0.3145\n",
      "Epoch 43, Train Loss: 0.3246, Val Loss: 0.3047\n",
      "Epoch 44, Train Loss: 0.3139, Val Loss: 0.2953\n",
      "Epoch 45, Train Loss: 0.3050, Val Loss: 0.2863\n",
      "Epoch 46, Train Loss: 0.2974, Val Loss: 0.2778\n",
      "Epoch 47, Train Loss: 0.2904, Val Loss: 0.2695\n",
      "Epoch 48, Train Loss: 0.2817, Val Loss: 0.2615\n",
      "Epoch 49, Train Loss: 0.2742, Val Loss: 0.2539\n",
      "Epoch 50, Train Loss: 0.2669, Val Loss: 0.2467\n",
      "Epoch 51, Train Loss: 0.2599, Val Loss: 0.2398\n",
      "Epoch 52, Train Loss: 0.2548, Val Loss: 0.2333\n",
      "Epoch 53, Train Loss: 0.2485, Val Loss: 0.2271\n",
      "Epoch 54, Train Loss: 0.2426, Val Loss: 0.2212\n",
      "Epoch 55, Train Loss: 0.2368, Val Loss: 0.2158\n",
      "Epoch 56, Train Loss: 0.2314, Val Loss: 0.2103\n",
      "Epoch 57, Train Loss: 0.2275, Val Loss: 0.2052\n",
      "Epoch 58, Train Loss: 0.2223, Val Loss: 0.2006\n",
      "Epoch 59, Train Loss: 0.2179, Val Loss: 0.1961\n",
      "Epoch 60, Train Loss: 0.2133, Val Loss: 0.1918\n",
      "Epoch 61, Train Loss: 0.2097, Val Loss: 0.1878\n",
      "Epoch 62, Train Loss: 0.2054, Val Loss: 0.1839\n",
      "Epoch 63, Train Loss: 0.2023, Val Loss: 0.1802\n",
      "Epoch 64, Train Loss: 0.1998, Val Loss: 0.1768\n",
      "Epoch 65, Train Loss: 0.1946, Val Loss: 0.1735\n",
      "Epoch 66, Train Loss: 0.1932, Val Loss: 0.1704\n",
      "Epoch 67, Train Loss: 0.1904, Val Loss: 0.1675\n",
      "Epoch 68, Train Loss: 0.1872, Val Loss: 0.1646\n",
      "Epoch 69, Train Loss: 0.1843, Val Loss: 0.1619\n",
      "Epoch 70, Train Loss: 0.1813, Val Loss: 0.1594\n",
      "Epoch 71, Train Loss: 0.1791, Val Loss: 0.1569\n",
      "Epoch 72, Train Loss: 0.1767, Val Loss: 0.1549\n",
      "Epoch 73, Train Loss: 0.1749, Val Loss: 0.1527\n",
      "Epoch 74, Train Loss: 0.1727, Val Loss: 0.1506\n",
      "Epoch 75, Train Loss: 0.1711, Val Loss: 0.1487\n",
      "Epoch 76, Train Loss: 0.1691, Val Loss: 0.1468\n",
      "Epoch 77, Train Loss: 0.1668, Val Loss: 0.1450\n",
      "Epoch 78, Train Loss: 0.1655, Val Loss: 0.1433\n",
      "Epoch 79, Train Loss: 0.1637, Val Loss: 0.1417\n",
      "Epoch 80, Train Loss: 0.1624, Val Loss: 0.1401\n",
      "Epoch 81, Train Loss: 0.1618, Val Loss: 0.1387\n",
      "Epoch 82, Train Loss: 0.1591, Val Loss: 0.1374\n",
      "Epoch 83, Train Loss: 0.1585, Val Loss: 0.1360\n",
      "Epoch 84, Train Loss: 0.1565, Val Loss: 0.1348\n",
      "Epoch 85, Train Loss: 0.1555, Val Loss: 0.1336\n",
      "Epoch 86, Train Loss: 0.1539, Val Loss: 0.1324\n",
      "Epoch 87, Train Loss: 0.1533, Val Loss: 0.1312\n",
      "Epoch 88, Train Loss: 0.1507, Val Loss: 0.1302\n",
      "Epoch 89, Train Loss: 0.1504, Val Loss: 0.1294\n",
      "Epoch 90, Train Loss: 0.1487, Val Loss: 0.1286\n",
      "Epoch 91, Train Loss: 0.1487, Val Loss: 0.1276\n",
      "Epoch 92, Train Loss: 0.1479, Val Loss: 0.1267\n",
      "Epoch 93, Train Loss: 0.1469, Val Loss: 0.1259\n",
      "Epoch 94, Train Loss: 0.1456, Val Loss: 0.1250\n",
      "Epoch 95, Train Loss: 0.1440, Val Loss: 0.1242\n",
      "Epoch 96, Train Loss: 0.1437, Val Loss: 0.1237\n",
      "Epoch 97, Train Loss: 0.1428, Val Loss: 0.1230\n",
      "Epoch 98, Train Loss: 0.1417, Val Loss: 0.1223\n",
      "Epoch 99, Train Loss: 0.1409, Val Loss: 0.1218\n",
      "Epoch 100, Train Loss: 0.1398, Val Loss: 0.1211\n",
      "Epoch 101, Train Loss: 0.1393, Val Loss: 0.1205\n",
      "Epoch 102, Train Loss: 0.1375, Val Loss: 0.1199\n",
      "Epoch 103, Train Loss: 0.1380, Val Loss: 0.1192\n",
      "Epoch 104, Train Loss: 0.1378, Val Loss: 0.1187\n",
      "Epoch 105, Train Loss: 0.1346, Val Loss: 0.1181\n",
      "Epoch 106, Train Loss: 0.1353, Val Loss: 0.1176\n",
      "Epoch 107, Train Loss: 0.1350, Val Loss: 0.1171\n",
      "Epoch 108, Train Loss: 0.1344, Val Loss: 0.1166\n",
      "Epoch 109, Train Loss: 0.1330, Val Loss: 0.1162\n",
      "Epoch 110, Train Loss: 0.1330, Val Loss: 0.1158\n",
      "Epoch 111, Train Loss: 0.1318, Val Loss: 0.1155\n",
      "Epoch 112, Train Loss: 0.1317, Val Loss: 0.1150\n",
      "Epoch 113, Train Loss: 0.1314, Val Loss: 0.1146\n",
      "Epoch 114, Train Loss: 0.1311, Val Loss: 0.1142\n",
      "Epoch 115, Train Loss: 0.1302, Val Loss: 0.1139\n",
      "Epoch 116, Train Loss: 0.1300, Val Loss: 0.1135\n",
      "Epoch 117, Train Loss: 0.1280, Val Loss: 0.1131\n",
      "Epoch 118, Train Loss: 0.1276, Val Loss: 0.1128\n",
      "Epoch 119, Train Loss: 0.1274, Val Loss: 0.1125\n",
      "Epoch 120, Train Loss: 0.1272, Val Loss: 0.1122\n",
      "Epoch 121, Train Loss: 0.1267, Val Loss: 0.1120\n",
      "Epoch 122, Train Loss: 0.1259, Val Loss: 0.1118\n",
      "Epoch 123, Train Loss: 0.1254, Val Loss: 0.1117\n",
      "Epoch 124, Train Loss: 0.1254, Val Loss: 0.1114\n",
      "Epoch 125, Train Loss: 0.1237, Val Loss: 0.1112\n",
      "Epoch 126, Train Loss: 0.1232, Val Loss: 0.1110\n",
      "Epoch 127, Train Loss: 0.1224, Val Loss: 0.1107\n",
      "Epoch 128, Train Loss: 0.1219, Val Loss: 0.1106\n",
      "Epoch 129, Train Loss: 0.1229, Val Loss: 0.1104\n",
      "Epoch 130, Train Loss: 0.1219, Val Loss: 0.1102\n",
      "Epoch 131, Train Loss: 0.1208, Val Loss: 0.1100\n",
      "Epoch 132, Train Loss: 0.1200, Val Loss: 0.1097\n",
      "Epoch 133, Train Loss: 0.1211, Val Loss: 0.1095\n",
      "Epoch 134, Train Loss: 0.1189, Val Loss: 0.1093\n",
      "Epoch 135, Train Loss: 0.1196, Val Loss: 0.1091\n",
      "Epoch 136, Train Loss: 0.1195, Val Loss: 0.1090\n",
      "Epoch 137, Train Loss: 0.1178, Val Loss: 0.1089\n",
      "Epoch 138, Train Loss: 0.1173, Val Loss: 0.1087\n",
      "Epoch 139, Train Loss: 0.1176, Val Loss: 0.1085\n",
      "Epoch 140, Train Loss: 0.1184, Val Loss: 0.1084\n",
      "Epoch 141, Train Loss: 0.1164, Val Loss: 0.1083\n",
      "Epoch 142, Train Loss: 0.1162, Val Loss: 0.1080\n",
      "Epoch 143, Train Loss: 0.1154, Val Loss: 0.1080\n",
      "Epoch 144, Train Loss: 0.1162, Val Loss: 0.1079\n",
      "Epoch 145, Train Loss: 0.1159, Val Loss: 0.1078\n",
      "Epoch 146, Train Loss: 0.1149, Val Loss: 0.1077\n",
      "Epoch 147, Train Loss: 0.1141, Val Loss: 0.1076\n",
      "Epoch 148, Train Loss: 0.1126, Val Loss: 0.1073\n",
      "Epoch 149, Train Loss: 0.1144, Val Loss: 0.1072\n",
      "Epoch 150, Train Loss: 0.1129, Val Loss: 0.1071\n",
      "Epoch 151, Train Loss: 0.1124, Val Loss: 0.1070\n",
      "Epoch 152, Train Loss: 0.1127, Val Loss: 0.1069\n",
      "Epoch 153, Train Loss: 0.1116, Val Loss: 0.1068\n",
      "Epoch 154, Train Loss: 0.1116, Val Loss: 0.1069\n",
      "Epoch 155, Train Loss: 0.1102, Val Loss: 0.1068\n",
      "Epoch 156, Train Loss: 0.1095, Val Loss: 0.1067\n",
      "Epoch 157, Train Loss: 0.1100, Val Loss: 0.1067\n",
      "Epoch 158, Train Loss: 0.1095, Val Loss: 0.1066\n",
      "Epoch 159, Train Loss: 0.1082, Val Loss: 0.1065\n",
      "Epoch 160, Train Loss: 0.1089, Val Loss: 0.1065\n",
      "Epoch 161, Train Loss: 0.1083, Val Loss: 0.1065\n",
      "Epoch 162, Train Loss: 0.1072, Val Loss: 0.1064\n",
      "Epoch 163, Train Loss: 0.1067, Val Loss: 0.1063\n",
      "Epoch 164, Train Loss: 0.1074, Val Loss: 0.1063\n",
      "Epoch 165, Train Loss: 0.1061, Val Loss: 0.1062\n",
      "Epoch 166, Train Loss: 0.1061, Val Loss: 0.1062\n",
      "Epoch 167, Train Loss: 0.1055, Val Loss: 0.1061\n",
      "Epoch 168, Train Loss: 0.1059, Val Loss: 0.1062\n",
      "Epoch 169, Train Loss: 0.1054, Val Loss: 0.1060\n",
      "Epoch 170, Train Loss: 0.1042, Val Loss: 0.1061\n",
      "Epoch 171, Train Loss: 0.1040, Val Loss: 0.1060\n",
      "Epoch 172, Train Loss: 0.1041, Val Loss: 0.1060\n",
      "Epoch 173, Train Loss: 0.1028, Val Loss: 0.1059\n",
      "Epoch 174, Train Loss: 0.1036, Val Loss: 0.1060\n",
      "Epoch 175, Train Loss: 0.1035, Val Loss: 0.1058\n",
      "Epoch 176, Train Loss: 0.1036, Val Loss: 0.1058\n",
      "Epoch 177, Train Loss: 0.1019, Val Loss: 0.1061\n",
      "Epoch 178, Train Loss: 0.1018, Val Loss: 0.1056\n",
      "Epoch 179, Train Loss: 0.1015, Val Loss: 0.1056\n",
      "Epoch 180, Train Loss: 0.1009, Val Loss: 0.1057\n",
      "Epoch 181, Train Loss: 0.1011, Val Loss: 0.1058\n",
      "Epoch 182, Train Loss: 0.1008, Val Loss: 0.1058\n",
      "Epoch 183, Train Loss: 0.1010, Val Loss: 0.1057\n",
      "Epoch 184, Train Loss: 0.1012, Val Loss: 0.1057\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "counter = 0\n",
    "\n",
    "train_dataset = TensorDataset(X_tr_cnn, y_tr)\n",
    "val_dataset = TensorDataset(X_val_cnn, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "for epoch in range(300):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(xb).squeeze()\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "    avg_train_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            val_outputs = model(xb).squeeze()\n",
    "            loss = criterion(val_outputs, yb)\n",
    "            val_loss += loss.item() * xb.size(0)\n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        print(f\"Epoch {epoch}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30cec138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.9933\n",
      "Validation Precision: 0.9441\n",
      "Validation Accuracy: 0.9554\n",
      "Validation F1 Score: 0.9441\n",
      "Validation Recall: 0.9441\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Đánh giá mô hình trên tập validation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_outputs = model(X_val_cnn).squeeze()\n",
    "    val_probs = torch.sigmoid(val_outputs).cpu().numpy()\n",
    "    val_preds = (val_probs > 0.5)\n",
    "    y_true = y_val.cpu().numpy()\n",
    "    acc = accuracy_score(y_true, val_preds)\n",
    "    f1 = f1_score(y_true, val_preds)\n",
    "    precision = precision_score(y_true, val_preds)\n",
    "    recall = recall_score(y_true, val_preds)\n",
    "    auc = roc_auc_score(y_true, val_probs)\n",
    "    print(f\"Validation AUC: {auc:.4f}\")\n",
    "    print(f\"Validation Precision: {precision:.4f}\")\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "    print(f\"Validation F1 Score: {f1:.4f}\")\n",
    "    print(f\"Validation Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e5857ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_tensor = torch.tensor(test_X, dtype=torch.float32)\n",
    "    test_outputs = model(test_tensor).squeeze()\n",
    "    test_probs = torch.sigmoid(test_outputs).cpu().numpy()\n",
    "\n",
    "# Save probabilities to result.csv\n",
    "test_data.loc[valid_idx, 'is_turkey'] = test_probs\n",
    "test_data.loc[valid_idx, ['vid_id', 'is_turkey']].to_csv('result.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03382079",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a047fca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turkey_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
