{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1fe76e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.stats import randint\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e129ebb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>is_turkey</th>\n",
       "      <th>vid_id</th>\n",
       "      <th>end_time_seconds_youtube_clip</th>\n",
       "      <th>start_time_seconds_youtube_clip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...</td>\n",
       "      <td>0</td>\n",
       "      <td>kDCk3hLIVXo</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>DPcGzqHoo7Y</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...</td>\n",
       "      <td>1</td>\n",
       "      <td>7yM63MTHh5k</td>\n",
       "      <td>240</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>luG3RmUAxxM</td>\n",
       "      <td>520</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...</td>\n",
       "      <td>0</td>\n",
       "      <td>PIm3cjxTpOk</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>[[90, 105, 224, 173, 117, 88, 119, 2, 219, 59,...</td>\n",
       "      <td>0</td>\n",
       "      <td>AKIWjFmAMt8</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>[[132, 154, 242, 164, 181, 58, 154, 63, 163, 4...</td>\n",
       "      <td>0</td>\n",
       "      <td>QTRCw0xn6uc</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>[[148, 8, 171, 123, 241, 91, 126, 154, 96, 246...</td>\n",
       "      <td>1</td>\n",
       "      <td>DbJJoQfo3kc</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>[[166, 13, 201, 135, 190, 93, 71, 30, 139, 151...</td>\n",
       "      <td>0</td>\n",
       "      <td>opqJ1SZmyGk</td>\n",
       "      <td>200</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>[[165, 45, 191, 96, 255, 87, 97, 77, 152, 215,...</td>\n",
       "      <td>0</td>\n",
       "      <td>aFHQY8eX5LI</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1195 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        audio_embedding  is_turkey  \\\n",
       "0     [[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...          0   \n",
       "1     [[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...          1   \n",
       "2     [[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...          1   \n",
       "3     [[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...          1   \n",
       "4     [[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...          0   \n",
       "...                                                 ...        ...   \n",
       "1190  [[90, 105, 224, 173, 117, 88, 119, 2, 219, 59,...          0   \n",
       "1191  [[132, 154, 242, 164, 181, 58, 154, 63, 163, 4...          0   \n",
       "1192  [[148, 8, 171, 123, 241, 91, 126, 154, 96, 246...          1   \n",
       "1193  [[166, 13, 201, 135, 190, 93, 71, 30, 139, 151...          0   \n",
       "1194  [[165, 45, 191, 96, 255, 87, 97, 77, 152, 215,...          0   \n",
       "\n",
       "           vid_id  end_time_seconds_youtube_clip  \\\n",
       "0     kDCk3hLIVXo                             70   \n",
       "1     DPcGzqHoo7Y                             40   \n",
       "2     7yM63MTHh5k                            240   \n",
       "3     luG3RmUAxxM                            520   \n",
       "4     PIm3cjxTpOk                             10   \n",
       "...           ...                            ...   \n",
       "1190  AKIWjFmAMt8                             30   \n",
       "1191  QTRCw0xn6uc                             40   \n",
       "1192  DbJJoQfo3kc                             40   \n",
       "1193  opqJ1SZmyGk                            200   \n",
       "1194  aFHQY8eX5LI                             40   \n",
       "\n",
       "      start_time_seconds_youtube_clip  \n",
       "0                                  60  \n",
       "1                                  30  \n",
       "2                                 230  \n",
       "3                                 510  \n",
       "4                                   0  \n",
       "...                               ...  \n",
       "1190                               20  \n",
       "1191                               30  \n",
       "1192                               30  \n",
       "1193                              190  \n",
       "1194                               30  \n",
       "\n",
       "[1195 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../../dataset/train.json', 'r') as file:\n",
    "        train_data = json.load(file)\n",
    "\n",
    "pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a662f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>vid_id</th>\n",
       "      <th>end_time_seconds_youtube_clip</th>\n",
       "      <th>start_time_seconds_youtube_clip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[177, 20, 226, 132, 198, 81, 111, 59, 132, 18...</td>\n",
       "      <td>pyKh38FXD3E</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[169, 21, 204, 161, 195, 72, 60, 39, 152, 184...</td>\n",
       "      <td>THhP1idrWXA</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[165, 13, 198, 141, 199, 81, 173, 54, 119, 11...</td>\n",
       "      <td>jsw3T6GY2Nw</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[167, 18, 188, 159, 198, 63, 156, 36, 179, 22...</td>\n",
       "      <td>nFkXTMHcjMU</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[178, 32, 181, 100, 198, 46, 82, 83, 136, 227...</td>\n",
       "      <td>Au8g9kAlrLQ</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>[[153, 26, 118, 69, 255, 87, 153, 59, 125, 204...</td>\n",
       "      <td>lQOQR6HCGyE</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>[[159, 8, 163, 128, 172, 64, 36, 56, 110, 236,...</td>\n",
       "      <td>CqhPMjumTOA</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>[[78, 56, 132, 20, 92, 120, 6, 133, 191, 156, ...</td>\n",
       "      <td>Ccn2LQJc2MI</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>[[81, 115, 208, 104, 236, 91, 95, 71, 161, 152...</td>\n",
       "      <td>f6OhmrIdB-g</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>[[164, 21, 189, 141, 198, 32, 151, 69, 129, 16...</td>\n",
       "      <td>vCxGJelmAeg</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1196 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        audio_embedding       vid_id  \\\n",
       "0     [[177, 20, 226, 132, 198, 81, 111, 59, 132, 18...  pyKh38FXD3E   \n",
       "1     [[169, 21, 204, 161, 195, 72, 60, 39, 152, 184...  THhP1idrWXA   \n",
       "2     [[165, 13, 198, 141, 199, 81, 173, 54, 119, 11...  jsw3T6GY2Nw   \n",
       "3     [[167, 18, 188, 159, 198, 63, 156, 36, 179, 22...  nFkXTMHcjMU   \n",
       "4     [[178, 32, 181, 100, 198, 46, 82, 83, 136, 227...  Au8g9kAlrLQ   \n",
       "...                                                 ...          ...   \n",
       "1191  [[153, 26, 118, 69, 255, 87, 153, 59, 125, 204...  lQOQR6HCGyE   \n",
       "1192  [[159, 8, 163, 128, 172, 64, 36, 56, 110, 236,...  CqhPMjumTOA   \n",
       "1193  [[78, 56, 132, 20, 92, 120, 6, 133, 191, 156, ...  Ccn2LQJc2MI   \n",
       "1194  [[81, 115, 208, 104, 236, 91, 95, 71, 161, 152...  f6OhmrIdB-g   \n",
       "1195  [[164, 21, 189, 141, 198, 32, 151, 69, 129, 16...  vCxGJelmAeg   \n",
       "\n",
       "      end_time_seconds_youtube_clip  start_time_seconds_youtube_clip  \n",
       "0                                10                                0  \n",
       "1                                40                               30  \n",
       "2                                40                               30  \n",
       "3                                24                               14  \n",
       "4                                40                               30  \n",
       "...                             ...                              ...  \n",
       "1191                             11                                1  \n",
       "1192                             40                               30  \n",
       "1193                             40                               30  \n",
       "1194                             40                               30  \n",
       "1195                             20                               10  \n",
       "\n",
       "[1196 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../../dataset/test.json', 'r') as file:\n",
    "        test_data = json.load(file)\n",
    "\n",
    "pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4984085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        audio_embedding  is_turkey  \\\n",
      "0     [[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...          0   \n",
      "1     [[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...          1   \n",
      "2     [[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...          1   \n",
      "3     [[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...          1   \n",
      "4     [[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...          0   \n",
      "...                                                 ...        ...   \n",
      "1190  [[90, 105, 224, 173, 117, 88, 119, 2, 219, 59,...          0   \n",
      "1191  [[132, 154, 242, 164, 181, 58, 154, 63, 163, 4...          0   \n",
      "1192  [[148, 8, 171, 123, 241, 91, 126, 154, 96, 246...          1   \n",
      "1193  [[166, 13, 201, 135, 190, 93, 71, 30, 139, 151...          0   \n",
      "1194  [[165, 45, 191, 96, 255, 87, 97, 77, 152, 215,...          0   \n",
      "\n",
      "           vid_id  end_time_seconds_youtube_clip  \\\n",
      "0     kDCk3hLIVXo                             70   \n",
      "1     DPcGzqHoo7Y                             40   \n",
      "2     7yM63MTHh5k                            240   \n",
      "3     luG3RmUAxxM                            520   \n",
      "4     PIm3cjxTpOk                             10   \n",
      "...           ...                            ...   \n",
      "1190  AKIWjFmAMt8                             30   \n",
      "1191  QTRCw0xn6uc                             40   \n",
      "1192  DbJJoQfo3kc                             40   \n",
      "1193  opqJ1SZmyGk                            200   \n",
      "1194  aFHQY8eX5LI                             40   \n",
      "\n",
      "      start_time_seconds_youtube_clip  \n",
      "0                                  60  \n",
      "1                                  30  \n",
      "2                                 230  \n",
      "3                                 510  \n",
      "4                                   0  \n",
      "...                               ...  \n",
      "1190                               20  \n",
      "1191                               30  \n",
      "1192                               30  \n",
      "1193                              190  \n",
      "1194                               30  \n",
      "\n",
      "[1195 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame(train_data)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "424f796c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        audio_embedding       vid_id  \\\n",
      "0     [[177, 20, 226, 132, 198, 81, 111, 59, 132, 18...  pyKh38FXD3E   \n",
      "1     [[169, 21, 204, 161, 195, 72, 60, 39, 152, 184...  THhP1idrWXA   \n",
      "2     [[165, 13, 198, 141, 199, 81, 173, 54, 119, 11...  jsw3T6GY2Nw   \n",
      "3     [[167, 18, 188, 159, 198, 63, 156, 36, 179, 22...  nFkXTMHcjMU   \n",
      "4     [[178, 32, 181, 100, 198, 46, 82, 83, 136, 227...  Au8g9kAlrLQ   \n",
      "...                                                 ...          ...   \n",
      "1191  [[153, 26, 118, 69, 255, 87, 153, 59, 125, 204...  lQOQR6HCGyE   \n",
      "1192  [[159, 8, 163, 128, 172, 64, 36, 56, 110, 236,...  CqhPMjumTOA   \n",
      "1193  [[78, 56, 132, 20, 92, 120, 6, 133, 191, 156, ...  Ccn2LQJc2MI   \n",
      "1194  [[81, 115, 208, 104, 236, 91, 95, 71, 161, 152...  f6OhmrIdB-g   \n",
      "1195  [[164, 21, 189, 141, 198, 32, 151, 69, 129, 16...  vCxGJelmAeg   \n",
      "\n",
      "      end_time_seconds_youtube_clip  start_time_seconds_youtube_clip  \n",
      "0                                10                                0  \n",
      "1                                40                               30  \n",
      "2                                40                               30  \n",
      "3                                24                               14  \n",
      "4                                40                               30  \n",
      "...                             ...                              ...  \n",
      "1191                             11                                1  \n",
      "1192                             40                               30  \n",
      "1193                             40                               30  \n",
      "1194                             40                               30  \n",
      "1195                             20                               10  \n",
      "\n",
      "[1196 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.DataFrame(test_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "854099af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score   : 0.9838472143886694\n",
      "Accuracy    : 0.9164345403899722\n",
      "Precision   : 0.9459459459459459\n",
      "Recall      : 0.8641975308641975\n",
      "F1 Score    : 0.9032258064516129\n"
     ]
    }
   ],
   "source": [
    "# KẾT QUẢ CAO NHẤT\n",
    "# Random Forest với tham số tối ưu nhất \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split   \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score,\n",
    "    recall_score, f1_score, accuracy_score\n",
    ")\n",
    "\n",
    "train_X = np.stack(train_data['audio_embedding'].apply(lambda x: np.mean(x, axis=0)))\n",
    "train_Y = train_data['is_turkey'].values\n",
    "\n",
    "# Chỉ chọn test_data có embedding hợp lệ\n",
    "valid_idx = test_data['audio_embedding'].apply(lambda x: isinstance(x, list) and len(x) > 0)\n",
    "test_X = np.stack(test_data.loc[valid_idx, 'audio_embedding'].apply(lambda x: np.mean(x, axis=0)))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Z = scaler.fit_transform(train_X)\n",
    "test_Z = scaler.transform(test_X)\n",
    "\n",
    "train_Z, val_Z, train_Y, val_Y = train_test_split(Z, train_Y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=600,\n",
    "    max_depth=15,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(train_Z, train_Y)\n",
    "\n",
    "\n",
    "y_pred_prob = model.predict_proba(val_Z)[:, 1]\n",
    "y_pred = model.predict(val_Z)\n",
    "\n",
    "\n",
    "print(\"AUC Score   :\", roc_auc_score(val_Y, y_pred_prob))\n",
    "print(\"Accuracy    :\", accuracy_score(val_Y, y_pred))\n",
    "print(\"Precision   :\", precision_score(val_Y, y_pred))\n",
    "print(\"Recall      :\", recall_score(val_Y, y_pred))\n",
    "print(\"F1 Score    :\", f1_score(val_Y, y_pred))\n",
    "\n",
    "\n",
    "test_pred_prob = model.predict_proba(test_Z)[:, 1]\n",
    "\n",
    "\n",
    "test_data['is_turkey'] = np.nan\n",
    "test_data.loc[valid_idx, 'is_turkey'] = test_pred_prob\n",
    "\n",
    "\n",
    "test_data[['vid_id', 'is_turkey']].to_csv('result.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b43e9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['audio_embedding', 'vid_id', 'end_time_seconds_youtube_clip', 'start_time_seconds_youtube_clip', 'is_turkey']\n"
     ]
    }
   ],
   "source": [
    "print(test_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c71aeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.9815911512189007\n"
     ]
    }
   ],
   "source": [
    "# BASIC - Random Forest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split   \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "train_X = np.stack(train_data['audio_embedding'].apply(lambda x: np.mean(x, axis=0)))\n",
    "train_Y = train_data['is_turkey'].values\n",
    "\n",
    "# Chỉ chọn những dòng có audio_embedding hợp lệ\n",
    "valid_idx = test_data['audio_embedding'].apply(lambda x: isinstance(x, list) and len(x) > 0)\n",
    "\n",
    "\n",
    "test_X = np.stack(test_data.loc[valid_idx, 'audio_embedding'].apply(lambda x: np.mean(x, axis=0)))\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Z = scaler.fit_transform(train_X)\n",
    "test_Z = scaler.transform(test_X)\n",
    "\n",
    "\n",
    "train_Z, val_Z, train_Y, val_Y = train_test_split(Z, train_Y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(train_Z, train_Y)\n",
    "\n",
    "\n",
    "y_pred_prob = model.predict_proba(val_Z)[:, 1]\n",
    "print(\"AUC score:\", roc_auc_score(val_Y, y_pred_prob))\n",
    "\n",
    "\n",
    "test_pred_prob = model.predict_proba(test_Z)[:, 1]\n",
    "\n",
    "\n",
    "test_data['is_turkey'] = np.nan\n",
    "test_data.loc[valid_idx, 'is_turkey'] = test_pred_prob\n",
    "\n",
    "# (Tuỳ chọn) Nếu muốn thay NaN bằng 0.5 hoặc 0\n",
    "# test_data['is_turkey'].fillna(0.5, inplace=True)\n",
    "test_data[['vid_id', 'is_turkey']].to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df6076db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     41\u001b[39m grid_search = GridSearchCV(base_model, param_grid, cv=cv, scoring=\u001b[33m'\u001b[39m\u001b[33mroc_auc\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m, verbose=\u001b[32m1\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Tìm mô hình tốt nhất\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_Z\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Lấy model tốt nhất\u001b[39;00m\n\u001b[32m     47\u001b[39m best_model = grid_search.best_estimator_\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HK2_2025\\01_Machine_Learning\\Project\\turkey_env\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HK2_2025\\01_Machine_Learning\\Project\\turkey_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HK2_2025\\01_Machine_Learning\\Project\\turkey_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HK2_2025\\01_Machine_Learning\\Project\\turkey_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HK2_2025\\01_Machine_Learning\\Project\\turkey_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HK2_2025\\01_Machine_Learning\\Project\\turkey_env\\Lib\\site-packages\\joblib\\parallel.py:2071\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2065\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2071\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HK2_2025\\01_Machine_Learning\\Project\\turkey_env\\Lib\\site-packages\\joblib\\parallel.py:1681\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1678\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1680\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1681\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1683\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1684\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\HK2_2025\\01_Machine_Learning\\Project\\turkey_env\\Lib\\site-packages\\joblib\\parallel.py:1799\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1789\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1794\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1797\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1798\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1799\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1800\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1802\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1803\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1810\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Random Forest & GridSearchCV tìm bộ tham số tối ưu nhất\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score,\n",
    "    recall_score, f1_score, accuracy_score\n",
    ")\n",
    "\n",
    "# Tạo ma trận đặc trưng và nhãn\n",
    "train_X = np.stack(train_data['audio_embedding'].apply(lambda x: np.mean(x, axis=0)))\n",
    "train_Y = train_data['is_turkey'].values\n",
    "\n",
    "# Chỉ chọn test_data có embedding hợp lệ\n",
    "valid_idx = test_data['audio_embedding'].apply(lambda x: isinstance(x, list) and len(x) > 0)\n",
    "test_X = np.stack(test_data.loc[valid_idx, 'audio_embedding'].apply(lambda x: np.mean(x, axis=0)))\n",
    "\n",
    "# Chuẩn hóa\n",
    "scaler = StandardScaler()\n",
    "Z = scaler.fit_transform(train_X)\n",
    "test_Z = scaler.transform(test_X)\n",
    "\n",
    "# Tách tập train/val\n",
    "train_Z, val_Z, train_Y, val_Y = train_test_split(Z, train_Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Cài đặt mô hình và grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [600,1000],\n",
    "    'max_depth': [10, 15, None],\n",
    "    'min_samples_split': [1, 2,3, 5],\n",
    "    'min_samples_leaf': [1, 2,6],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "base_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(base_model, param_grid, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Tìm mô hình tốt nhất\n",
    "grid_search.fit(train_Z, train_Y)\n",
    "\n",
    "# Lấy model tốt nhất\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Dự đoán trên tập validation\n",
    "y_pred_prob = best_model.predict_proba(val_Z)[:, 1]\n",
    "y_pred = best_model.predict(val_Z)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "print(\"AUC Score   :\", roc_auc_score(val_Y, y_pred_prob))\n",
    "print(\"Accuracy    :\", accuracy_score(val_Y, y_pred))\n",
    "print(\"Precision   :\", precision_score(val_Y, y_pred))\n",
    "print(\"Recall      :\", recall_score(val_Y, y_pred))\n",
    "print(\"F1 Score    :\", f1_score(val_Y, y_pred))\n",
    "\n",
    "# Dự đoán trên test\n",
    "test_pred_prob = best_model.predict_proba(test_Z)[:, 1]\n",
    "\n",
    "# Gán kết quả\n",
    "test_data['is_turkey'] = np.nan\n",
    "test_data.loc[valid_idx, 'is_turkey'] = test_pred_prob\n",
    "\n",
    "# Lưu kết quả\n",
    "test_data[['vid_id', 'is_turkey']].to_csv('result.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SO SÁNH NHIỀU MODELS: \n",
    "# KẾT QUẢ: RandomForest tốt nhất \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import warnings\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.metrics import (\n",
    "#     roc_auc_score, precision_score, recall_score,\n",
    "#     f1_score, accuracy_score\n",
    "# )\n",
    "\n",
    "# from lightgbm import LGBMClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "# # Tắt toàn bộ cảnh báo\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# # Chuẩn bị dữ liệu huấn luyện\n",
    "# train_X = np.stack(train_data['audio_embedding'].apply(lambda x: np.mean(x, axis=0)))\n",
    "# train_Y = train_data['is_turkey'].values\n",
    "\n",
    "# # Lọc những dòng test có audio_embedding hợp lệ\n",
    "# valid_idx = test_data['audio_embedding'].apply(lambda x: isinstance(x, list) and len(x) > 0)\n",
    "# test_X = np.stack(test_data.loc[valid_idx, 'audio_embedding'].apply(lambda x: np.mean(x, axis=0)))\n",
    "\n",
    "# # Chuẩn hóa dữ liệu\n",
    "# scaler = StandardScaler()\n",
    "# Z = scaler.fit_transform(train_X)\n",
    "# test_Z = scaler.transform(test_X)\n",
    "\n",
    "# # Chia train / validation\n",
    "# train_Z, val_Z, train_Y, val_Y = train_test_split(Z, train_Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Các mô hình cần đánh giá\n",
    "# models = {\n",
    "#     'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "#     'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "#     'GaussianNB': GaussianNB(),\n",
    "#     'LightGBM': LGBMClassifier(random_state=42, verbose=-1),\n",
    "#     'XGBoost': XGBClassifier(verbosity=0, random_state=42),\n",
    "#     'CatBoost': CatBoostClassifier(verbose=0, random_seed=42)\n",
    "# }\n",
    "\n",
    "# # Đánh giá từng mô hình\n",
    "# for name, model in models.items():\n",
    "#     model.fit(train_Z, train_Y)\n",
    "\n",
    "#     # Với LightGBM cần convert về DataFrame để tránh cảnh báo\n",
    "#     if name == 'LightGBM':\n",
    "#         val_input = pd.DataFrame(val_Z)\n",
    "#     else:\n",
    "#         val_input = val_Z\n",
    "\n",
    "#     val_pred_prob = model.predict_proba(val_input)[:, 1]\n",
    "#     val_pred = model.predict(val_input)\n",
    "\n",
    "#     auc = roc_auc_score(val_Y, val_pred_prob)\n",
    "#     precision = precision_score(val_Y, val_pred)\n",
    "#     recall = recall_score(val_Y, val_pred)\n",
    "#     f1 = f1_score(val_Y, val_pred)\n",
    "#     accuracy = accuracy_score(val_Y, val_pred)\n",
    "\n",
    "#     print(f\"\\n{name} Results:\")\n",
    "#     print(f\"AUC Score     : {auc:.4f}\")\n",
    "#     print(f\"Precision     : {precision:.4f}\")\n",
    "#     print(f\"Recall        : {recall:.4f}\")\n",
    "#     print(f\"F1 Score      : {f1:.4f}\")\n",
    "#     print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "\n",
    "# # Chọn mô hình tốt nhất, ví dụ: LightGBM\n",
    "# final_model = models['LightGBM']\n",
    "# final_test_input = pd.DataFrame(test_Z)\n",
    "# test_pred_prob = final_model.predict_proba(final_test_input)[:, 1]\n",
    "\n",
    "# # Gán kết quả vào test_data\n",
    "# test_data['is_turkey'] = np.nan\n",
    "# test_data.loc[valid_idx, 'is_turkey'] = test_pred_prob\n",
    "\n",
    "# # Ghi kết quả ra file\n",
    "# test_data[['vid_id', 'is_turkey']].to_csv('result.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turkey_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
