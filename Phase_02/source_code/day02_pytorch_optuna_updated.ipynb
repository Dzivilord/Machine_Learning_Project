{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2dadd7e",
   "metadata": {},
   "source": [
    "# Phase 2: MLP - PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d6611d",
   "metadata": {},
   "source": [
    "## Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "1a952eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e892eed0",
   "metadata": {},
   "source": [
    "## Đọc dữ liệu huấn luyện và dữ liệu test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "1fb28697",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data=\".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "9d10cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_data+'/train.json','r') as f:\n",
    "    train_data = json.load(f)\n",
    "with open(path_to_data+'/test.json','r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "# Chuyển  dữ liệu thành DataFrame để dễ quan sát\n",
    "train_df = pd.DataFrame(train_data)\n",
    "test_df = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "2c22d7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>is_turkey</th>\n",
       "      <th>vid_id</th>\n",
       "      <th>end_time_seconds_youtube_clip</th>\n",
       "      <th>start_time_seconds_youtube_clip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...</td>\n",
       "      <td>0</td>\n",
       "      <td>kDCk3hLIVXo</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>DPcGzqHoo7Y</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...</td>\n",
       "      <td>1</td>\n",
       "      <td>7yM63MTHh5k</td>\n",
       "      <td>240</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>luG3RmUAxxM</td>\n",
       "      <td>520</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...</td>\n",
       "      <td>0</td>\n",
       "      <td>PIm3cjxTpOk</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     audio_embedding  is_turkey       vid_id  \\\n",
       "0  [[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...          0  kDCk3hLIVXo   \n",
       "1  [[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...          1  DPcGzqHoo7Y   \n",
       "2  [[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...          1  7yM63MTHh5k   \n",
       "3  [[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...          1  luG3RmUAxxM   \n",
       "4  [[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...          0  PIm3cjxTpOk   \n",
       "\n",
       "   end_time_seconds_youtube_clip  start_time_seconds_youtube_clip  \n",
       "0                             70                               60  \n",
       "1                             40                               30  \n",
       "2                            240                              230  \n",
       "3                            520                              510  \n",
       "4                             10                                0  "
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In ra dữ liệu huấn luyện\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "6cf29e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>vid_id</th>\n",
       "      <th>end_time_seconds_youtube_clip</th>\n",
       "      <th>start_time_seconds_youtube_clip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[177, 20, 226, 132, 198, 81, 111, 59, 132, 18...</td>\n",
       "      <td>pyKh38FXD3E</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[169, 21, 204, 161, 195, 72, 60, 39, 152, 184...</td>\n",
       "      <td>THhP1idrWXA</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[165, 13, 198, 141, 199, 81, 173, 54, 119, 11...</td>\n",
       "      <td>jsw3T6GY2Nw</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[167, 18, 188, 159, 198, 63, 156, 36, 179, 22...</td>\n",
       "      <td>nFkXTMHcjMU</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[178, 32, 181, 100, 198, 46, 82, 83, 136, 227...</td>\n",
       "      <td>Au8g9kAlrLQ</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     audio_embedding       vid_id  \\\n",
       "0  [[177, 20, 226, 132, 198, 81, 111, 59, 132, 18...  pyKh38FXD3E   \n",
       "1  [[169, 21, 204, 161, 195, 72, 60, 39, 152, 184...  THhP1idrWXA   \n",
       "2  [[165, 13, 198, 141, 199, 81, 173, 54, 119, 11...  jsw3T6GY2Nw   \n",
       "3  [[167, 18, 188, 159, 198, 63, 156, 36, 179, 22...  nFkXTMHcjMU   \n",
       "4  [[178, 32, 181, 100, 198, 46, 82, 83, 136, 227...  Au8g9kAlrLQ   \n",
       "\n",
       "   end_time_seconds_youtube_clip  start_time_seconds_youtube_clip  \n",
       "0                             10                                0  \n",
       "1                             40                               30  \n",
       "2                             40                               30  \n",
       "3                             24                               14  \n",
       "4                             40                               30  "
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In ra dữ liệu kiểm tra\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a3b9b",
   "metadata": {},
   "source": [
    "## Phát triển mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bc698f",
   "metadata": {},
   "source": [
    "### Xử lý dữ liệu trước khi huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "60982dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_embeddings(embeddings): # Hàm dùng để tính toán trên embeddings\n",
    "    X= np.array(embeddings)\n",
    "    mean= np.mean(X, axis=0)\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "75de7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.stack(train_df['audio_embedding'].apply(combined_embeddings)) # Lấy trung bình của mỗi cột trong các audio_embedding\n",
    "train_Y = train_df['is_turkey'].values # Lấy nhãn của dữ liệu huấn luyện\n",
    "\n",
    "valid_idx = test_df['audio_embedding'].apply(lambda x: isinstance(x, list) and len(x) > 0)\n",
    "test_X = np.stack(test_df['audio_embedding'].apply(combined_embeddings)) # Lấy trung bình của mỗi cột trong các audio_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "c23fc8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= StandardScaler()\n",
    "# Chuẩn hóa dữ liệu\n",
    "\n",
    "train_X = scaler.fit_transform(train_X)\n",
    "test_X = scaler.transform(test_X)\n",
    "# Chia dữ liệu huấn luyện thành tập huấn luyện và tập kiểm tra\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_Y, test_size=0.15, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a711c1",
   "metadata": {},
   "source": [
    "### Chuyển dataset thành kiểu dữ liệu phù hợp với PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "ee1f7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)  # Chuyển đổi dữ liệu thành tensor\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).unsqueeze(1) if y is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.X[idx], self.y[idx]\n",
    "        return self.X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "97f8cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds= MyDataset(X_train, y_train)\n",
    "val_ds = MyDataset(X_val, y_val)\n",
    "test_ds = MyDataset(test_X)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader= DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56979bf9",
   "metadata": {},
   "source": [
    "### Xây dựng mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "b65f8adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, dim, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(dim, dim)\n",
    "        self.bn = nn.BatchNorm1d(dim)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.dropout(out)\n",
    "        return self.relu(out + x)  # Residual connection\n",
    "        \n",
    "class ResidualMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.res_block = ResidualBlock(hidden_dim, dropout)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.res_block(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "6d9ca4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Khởi tạo mô hình với kích thước đầu vào\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad558b0",
   "metadata": {},
   "source": [
    "### EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "03d40e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self,patience=5,delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss= None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "    def __call__(self,val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da75e30b",
   "metadata": {},
   "source": [
    "## Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "bc0b46ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.001  # Tính trọng số cho lớp dương"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "1bfcabf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hiddens, dropouts,learning_rates,weight_decays):\n",
    "    best_model= None\n",
    "    criterion = nn.BCELoss()\n",
    "    for hidden in hiddens:\n",
    "        for dropout in dropouts:\n",
    "            for lr in learning_rates:\n",
    "                for weight_decay in weight_decays:\n",
    "                    print(f\"Training with hidden={hidden}, dropout={dropout}, learning_rate={lr}, weight_decay={weight_decay}\")\n",
    "                    accs=[]\n",
    "                    precs=[]\n",
    "                    recs=[]\n",
    "                    f1s=[]\n",
    "                    roc_aucs=[]\n",
    "\n",
    "                    for iter in range(10):\n",
    "                    \n",
    "                        # Khởi tạo mô hình với các tham số hiện tại\n",
    "                        model = ResidualMLP(input_dim=X_train.shape[1], hidden_dim=hidden, dropout=dropout)\n",
    "                        optimizer=optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)\n",
    "                        early_stopping = EarlyStopping(patience=5)\n",
    "                        for epoch in range(num_epochs):\n",
    "                            model.train()\n",
    "                            total_loss = 0\n",
    "                            for X_batch, y_batch in train_loader:\n",
    "                                optimizer.zero_grad()\n",
    "                                output = model(X_batch)\n",
    "                                loss = criterion(output, y_batch)\n",
    "                                loss.backward()\n",
    "                                optimizer.step()\n",
    "                                total_loss += loss.item()\n",
    "\n",
    "                            model.eval()\n",
    "                            val_loss=0\n",
    "                            with torch.no_grad():\n",
    "                                for X_batch, y_batch in val_loader:\n",
    "                                    val_output = model(X_batch)\n",
    "                                    loss = criterion(val_output, y_batch)\n",
    "                                    val_loss += loss.item()\n",
    "                            val_loss /= len(val_loader)\n",
    "                            early_stopping(val_loss)\n",
    "                            if early_stopping.early_stop:\n",
    "                                break\n",
    "\n",
    "                        model.eval()\n",
    "                        y_true = []\n",
    "                        y_pred = []\n",
    "                        y_prob = []\n",
    "\n",
    "                        with torch.no_grad():\n",
    "                            for X_batch, y_batch in val_loader:\n",
    "                                output = model(X_batch)\n",
    "                                probs = output.squeeze().numpy()\n",
    "                                preds = (output > 0.5).int().squeeze().numpy()\n",
    "                                y_true.extend(y_batch.squeeze().numpy())\n",
    "                                y_pred.extend(preds)\n",
    "                                y_prob.extend(probs)\n",
    "\n",
    "                        # Metrics\n",
    "                        roc_auc = roc_auc_score(y_true, y_prob)\n",
    "                        acc = accuracy_score(y_true, y_pred)\n",
    "                        prec = precision_score(y_true, y_pred)\n",
    "                        rec = recall_score(y_true, y_pred)\n",
    "                        f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "                        accs.append(acc)\n",
    "                        precs.append(prec)\n",
    "                        recs.append(rec)\n",
    "                        f1s.append(f1)\n",
    "                        roc_aucs.append(roc_auc)\n",
    "                    \n",
    "                    avg_acc = np.mean(accs)\n",
    "                    avg_prec = np.mean(precs)\n",
    "                    avg_rec = np.mean(recs)\n",
    "                    avg_f1 = np.mean(f1s)\n",
    "                    avg_roc_auc = np.mean(roc_aucs)\n",
    "                    print(f\"ROC AUC: {avg_roc_auc:.4f}, Accuracy: {avg_acc:.4f}, Precision: {avg_prec:.4f}, Recall: {avg_rec:.4f}, F1 Score: {avg_f1:.4f}\")\n",
    "\n",
    "                    if best_model is None or (avg_roc_auc > best_model['roc_auc'] and (avg_acc+ avg_prec + avg_rec + avg_f1) / 4 > (best_model['accuracy'] + best_model['precision'] + best_model['recall'] + best_model['f1_score']) / 4):\n",
    "                        best_model = {\n",
    "                            'model': model,\n",
    "                            'hidden': hidden,\n",
    "                            'dropout': dropout,\n",
    "                            'learning_rate': lr,\n",
    "                            'weight_decay': weight_decay,\n",
    "                            'roc_auc': avg_roc_auc,\n",
    "                            'accuracy': avg_acc,\n",
    "                            'precision': avg_prec,\n",
    "                            'recall': avg_rec,\n",
    "                            'f1_score': avg_f1\n",
    "                            }\n",
    "    print(f\"Best model found with ROC AUC: {best_model['roc_auc']:.4f}, hidden={best_model['hidden']}, dropout={best_model['dropout']}, learning_rate={best_model['learning_rate']}, weight_decay={best_model['weight_decay']}\")\n",
    "    return best_model\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "23d75681",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiddens=[32,64,128]\n",
    "dropouts=[0,0.05,0.1]\n",
    "learning_rates=[0.05]\n",
    "weight_decays=[0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "f2d8a49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hidden=32, dropout=0, learning_rate=0.05, weight_decay=0.01\n",
      "ROC AUC: 0.9763, Accuracy: 0.9089, Precision: 0.9269, Recall: 0.8762, F1 Score: 0.8995\n",
      "Training with hidden=32, dropout=0.05, learning_rate=0.05, weight_decay=0.01\n",
      "ROC AUC: 0.9779, Accuracy: 0.9111, Precision: 0.9310, Recall: 0.8762, F1 Score: 0.9016\n",
      "Training with hidden=32, dropout=0.1, learning_rate=0.05, weight_decay=0.01\n",
      "ROC AUC: 0.9762, Accuracy: 0.9100, Precision: 0.9256, Recall: 0.8798, F1 Score: 0.9011\n",
      "Training with hidden=64, dropout=0, learning_rate=0.05, weight_decay=0.01\n",
      "ROC AUC: 0.9767, Accuracy: 0.9044, Precision: 0.9270, Recall: 0.8655, F1 Score: 0.8935\n",
      "Training with hidden=64, dropout=0.05, learning_rate=0.05, weight_decay=0.01\n",
      "ROC AUC: 0.9762, Accuracy: 0.9089, Precision: 0.9246, Recall: 0.8786, F1 Score: 0.8996\n",
      "Training with hidden=64, dropout=0.1, learning_rate=0.05, weight_decay=0.01\n",
      "ROC AUC: 0.9776, Accuracy: 0.9172, Precision: 0.9383, Recall: 0.8821, F1 Score: 0.9084\n",
      "Training with hidden=128, dropout=0, learning_rate=0.05, weight_decay=0.01\n",
      "ROC AUC: 0.9747, Accuracy: 0.9067, Precision: 0.9393, Recall: 0.8583, F1 Score: 0.8949\n",
      "Training with hidden=128, dropout=0.05, learning_rate=0.05, weight_decay=0.01\n",
      "ROC AUC: 0.9763, Accuracy: 0.9122, Precision: 0.9341, Recall: 0.8750, F1 Score: 0.9025\n",
      "Training with hidden=128, dropout=0.1, learning_rate=0.05, weight_decay=0.01\n",
      "ROC AUC: 0.9784, Accuracy: 0.9078, Precision: 0.9369, Recall: 0.8631, F1 Score: 0.8971\n",
      "Best model found with ROC AUC: 0.9779, hidden=32, dropout=0.05, learning_rate=0.05, weight_decay=0.01\n"
     ]
    }
   ],
   "source": [
    "best_model = train_model(hiddens, dropouts, learning_rates, weight_decays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "f6be3aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics of the best model:\n",
      "ROC AUC: 0.9779, Accuracy: 0.9111, Precision: 0.9310, Recall: 0.8762, F1 Score: 0.9016\n"
     ]
    }
   ],
   "source": [
    "print(\"Metrics of the best model:\")\n",
    "print(f\"ROC AUC: {best_model['roc_auc']:.4f}, Accuracy: {best_model['accuracy']:.4f}, Precision: {best_model['precision']:.4f}, Recall: {best_model['recall']:.4f}, F1 Score: {best_model['f1_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "476f9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = nn.BCELoss() # Sử dụng hàm mất mát nhị phân với logits\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay=0.1)\n",
    "# early_stopping = EarlyStopping(patience=5)  # Khởi tạo EarlyStopping\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for X_batch, y_batch in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(X_batch)\n",
    "#         loss = criterion(output, y_batch)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item()\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "#     model.eval()\n",
    "#     val_loss=0\n",
    "#     with torch.no_grad():\n",
    "#         for X_batch, y_batch in val_loader:\n",
    "#             val_output = model(X_batch)\n",
    "#             loss = criterion(val_output, y_batch)\n",
    "#             val_loss += loss.item()\n",
    "#     val_loss /= len(val_loader)\n",
    "#     print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "#     early_stopping(val_loss)\n",
    "#     if early_stopping.early_stop:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "b19bef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "# y_prob = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for X_batch, y_batch in val_loader:\n",
    "#         output = model(X_batch)\n",
    "#         probs = output.squeeze().numpy()\n",
    "#         preds = (output > 0.5).int().squeeze().numpy()\n",
    "#         y_true.extend(y_batch.squeeze().numpy())\n",
    "#         y_pred.extend(preds)\n",
    "#         y_prob.extend(probs)\n",
    "\n",
    "# # Metrics\n",
    "# acc = accuracy_score(y_true, y_pred)\n",
    "# prec = precision_score(y_true, y_pred)\n",
    "# rec = recall_score(y_true, y_pred)\n",
    "# f1 = f1_score(y_true, y_pred)\n",
    "# roc_auc = roc_auc_score(y_true, y_prob)\n",
    "\n",
    "# print(f\"ROC AUC: {roc_auc}\")\n",
    "# print(f\"Accuracy: {acc}\")\n",
    "# print(f\"Precision: {prec}\")\n",
    "# print(f\"Recall: {rec}\")\n",
    "# print(f\"F1-Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101544f7",
   "metadata": {},
   "source": [
    "### Dự đoán trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "23315719",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= best_model['model']  # Sử dụng mô hình tốt nhất từ quá trình huấn luyện\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    probs=model(test_ds.X).squeeze().tolist()\n",
    "\n",
    "\n",
    "for item,prob in zip(test_df['vid_id'], probs):\n",
    "    test_df.loc[test_df['vid_id'] == item, 'is_turkey'] = round(prob,6)\n",
    "\n",
    "test_df[['vid_id', 'is_turkey']].to_csv('result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
