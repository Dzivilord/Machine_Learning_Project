{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73fda9de",
   "metadata": {},
   "source": [
    "# Huấn luyện với tách data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3eec2a",
   "metadata": {},
   "source": [
    "# Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "468c6467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader,random_split,TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm \n",
    "import tqdm as notebook_tqdm\n",
    "import torchaudio\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9e99ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27a97a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version:  3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]\n",
      "PyTorch version:  2.7.0+cpu\n",
      "Torchvision version:  0.22.0+cpu\n",
      "Numpy version:  2.1.3\n",
      "Pandas version:  2.2.3\n"
     ]
    }
   ],
   "source": [
    "print(\"System version: \", sys.version)\n",
    "print(\"PyTorch version: \", torch.__version__)\n",
    "print(\"Torchvision version: \", torchvision.__version__)\n",
    "print(\"Numpy version: \", np.__version__)\n",
    "print(\"Pandas version: \", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96833ccc",
   "metadata": {},
   "source": [
    "# Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "448f4788",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data='../../dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "99a22326",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_to_data+'/train.json', 'r') as f:\n",
    "    train_val_data = json.load(f)\n",
    "with open(path_to_data+'/test.json', 'r') as f:\n",
    "    test_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c38ee97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_data=pd.DataFrame(train_val_data)\n",
    "test_data=pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66d2efeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1196, 4)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a51a6fd",
   "metadata": {},
   "source": [
    "# Tách list vector thành các vector/ mẫu mới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5e0d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_audio_embeddings(data):\n",
    "    expanded_rows = []\n",
    "    for idx, row in data.iterrows():\n",
    "        embeddings = row['audio_embedding']\n",
    "        for emb in embeddings:\n",
    "            new_row = row.copy()\n",
    "            new_row['audio_embedding'] = emb\n",
    "            expanded_rows.append(new_row)\n",
    "    expanded_data = pd.DataFrame(expanded_rows)\n",
    "    expanded_data.reset_index(drop=True, inplace=True)\n",
    "    return expanded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abe7dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_train_val_data = expand_audio_embeddings(train_val_data)\n",
    "expanded_test_data = expand_audio_embeddings(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "972b07d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_turkey\n",
       "0    6954\n",
       "1    4841\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_train_val_data['is_turkey'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69ad757f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>is_turkey</th>\n",
       "      <th>vid_id</th>\n",
       "      <th>end_time_seconds_youtube_clip</th>\n",
       "      <th>start_time_seconds_youtube_clip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[172, 34, 216, 110, 208, 46, 95, 66, 161, 125,...</td>\n",
       "      <td>0</td>\n",
       "      <td>kDCk3hLIVXo</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[171, 39, 199, 121, 238, 62, 59, 61, 170, 146,...</td>\n",
       "      <td>0</td>\n",
       "      <td>kDCk3hLIVXo</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[169, 33, 200, 97, 210, 22, 73, 51, 169, 129, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>kDCk3hLIVXo</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[180, 39, 218, 118, 213, 73, 80, 43, 160, 147,...</td>\n",
       "      <td>0</td>\n",
       "      <td>kDCk3hLIVXo</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[166, 31, 204, 134, 211, 59, 62, 73, 187, 167,...</td>\n",
       "      <td>0</td>\n",
       "      <td>kDCk3hLIVXo</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     audio_embedding  is_turkey       vid_id  \\\n",
       "0  [172, 34, 216, 110, 208, 46, 95, 66, 161, 125,...          0  kDCk3hLIVXo   \n",
       "1  [171, 39, 199, 121, 238, 62, 59, 61, 170, 146,...          0  kDCk3hLIVXo   \n",
       "2  [169, 33, 200, 97, 210, 22, 73, 51, 169, 129, ...          0  kDCk3hLIVXo   \n",
       "3  [180, 39, 218, 118, 213, 73, 80, 43, 160, 147,...          0  kDCk3hLIVXo   \n",
       "4  [166, 31, 204, 134, 211, 59, 62, 73, 187, 167,...          0  kDCk3hLIVXo   \n",
       "\n",
       "   end_time_seconds_youtube_clip  start_time_seconds_youtube_clip  \n",
       "0                             70                               60  \n",
       "1                             70                               60  \n",
       "2                             70                               60  \n",
       "3                             70                               60  \n",
       "4                             70                               60  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_train_val_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47852c67",
   "metadata": {},
   "source": [
    "# Tính vector trung bình nếu dùng list vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28bd99e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_embeddings(embeddings): \n",
    "    X= np.array(embeddings)\n",
    "    return np.mean(X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37228586",
   "metadata": {},
   "source": [
    "# Trích thuộc tính và đặc trưng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb8ebd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val=pd.DataFrame(expanded_train_val_data['audio_embedding'])\n",
    "Y_train_val=pd.DataFrame(expanded_train_val_data['is_turkey'])\n",
    "X_test=pd.DataFrame(expanded_test_data['audio_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f55b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = pd.DataFrame(X_train_val['audio_embedding'].tolist(), columns=[f'feature_{i}' for i in range(128)])\n",
    "X_test_features = pd.DataFrame(X_test['audio_embedding'].tolist(), columns=[f'feature_{i}' for i in range(128)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9003a45",
   "metadata": {},
   "source": [
    "# Chuyển đổi dữ liệu chuẩn bị học"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "febc706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler= StandardScaler()\n",
    "\n",
    "train_X = scaler.fit_transform(audio_features)\n",
    "test_X = scaler.transform(X_test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c251d3d",
   "metadata": {},
   "source": [
    "# Chuyển dataset thành kiểu dữ liệu phù hợp cho pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e85b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_X_train= torch.tensor(train_X, dtype=torch.float32)\n",
    "torch_Y_train= torch.tensor(Y_train_val['is_turkey'].values, dtype=torch.float32)\n",
    "torch_X_test= torch.tensor(test_X, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6e79bded",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=TensorDataset(torch_X_train, torch_Y_train)\n",
    "train_size=int(0.8 * len(dataset))\n",
    "val_size=len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b16fa",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b23356",
   "metadata": {},
   "source": [
    "## Chuyển thành DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a106dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213b82c7",
   "metadata": {},
   "source": [
    "## Cấu hình mạng neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c676ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=128, hidden_dim1=128, hidden_dim2=64,hidden_dim3=32, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.BatchNorm1d(hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.BatchNorm1d(hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(hidden_dim2, hidden_dim3),\n",
    "            nn.BatchNorm1d(hidden_dim3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(hidden_dim3, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61767ee7",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50018255",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self,patience=5,delta=0):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss= None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "    def __call__(self,val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35b435e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier()\n",
    "loss_fn = nn.BCELoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3,weight_decay=0.001)\n",
    "early_stopping = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e87052",
   "metadata": {},
   "source": [
    "### Huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cc066d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 28.2721\n",
      "Validation Loss: 0.2692\n",
      "Epoch 2, Loss: 19.2360\n",
      "Validation Loss: 0.2384\n",
      "Epoch 3, Loss: 16.9694\n",
      "Validation Loss: 0.2353\n",
      "Epoch 4, Loss: 16.0874\n",
      "Validation Loss: 0.2301\n",
      "Epoch 5, Loss: 15.0459\n",
      "Validation Loss: 0.2194\n",
      "Epoch 6, Loss: 14.2060\n",
      "Validation Loss: 0.2208\n",
      "Epoch 7, Loss: 13.3737\n",
      "Validation Loss: 0.2256\n",
      "Epoch 8, Loss: 12.9425\n",
      "Validation Loss: 0.2175\n",
      "Epoch 9, Loss: 11.9787\n",
      "Validation Loss: 0.2173\n",
      "Epoch 10, Loss: 11.2525\n",
      "Validation Loss: 0.2229\n",
      "Epoch 11, Loss: 11.2759\n",
      "Validation Loss: 0.2286\n",
      "Epoch 12, Loss: 10.3326\n",
      "Validation Loss: 0.2276\n",
      "Epoch 13, Loss: 9.6408\n",
      "Validation Loss: 0.2390\n",
      "Epoch 14, Loss: 9.7163\n",
      "Validation Loss: 0.2333\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_Y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch_X).squeeze()  # [batch_size]\n",
    "        loss = loss_fn(output, batch_Y.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            val_output = model(X_batch).squeeze()\n",
    "            loss = loss_fn(val_output, y_batch.float())\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "    early_stopping(val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5038cf3a",
   "metadata": {},
   "source": [
    "### Đánh giá chỉ số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "222fcd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9691\n",
      "Accuracy: 0.9224\n",
      "Precision: 0.9085\n",
      "Recall: 0.9020\n",
      "F1-score: 0.9052\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_Y in val_loader:\n",
    "        output = model(batch_X).squeeze()\n",
    "        probs = output.detach().cpu().numpy()\n",
    "        preds = (output >= 0.5).long().cpu().numpy()\n",
    "        all_labels.extend(batch_Y.cpu().numpy())\n",
    "        all_preds.extend(preds)\n",
    "        all_probs.extend(probs)\n",
    "\n",
    "accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
    "auc = roc_auc_score(all_labels, all_probs)\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6e710",
   "metadata": {},
   "source": [
    "# Dự đoán kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a7505ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(torch_X_test).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49feb601",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame({\n",
    "    'vid_id': test_data['vid_id'],\n",
    "    'is_turkey': np.round(outputs.numpy()[:len(test_data)], 6)\n",
    "})\n",
    "result_df.to_csv('result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turkey_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
